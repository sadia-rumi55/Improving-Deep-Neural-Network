{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initialization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+TB9TCnnEJst8zuZoYXCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadia-rumi55/Improving-Deep-Neural-Network/blob/master/initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MNRF5_woZLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "\n",
        "from utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagation\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util, update_parameters, predict, load_dataset, plot_decision_boundary, predict_dec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# load image dataset: blue/red dots in circles\n",
        "train_X, train_Y, test_X, test_Y = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8PDMoJUonwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, Y, learning_rate=0.01, num_iterations=15000, print_cost=True, initialization=\"he\"):\n",
        "    \"\"\"\n",
        "    Implements a three-layer neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (2, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)\n",
        "    learning_rate -- learning rate for gradient descent \n",
        "    num_iterations -- number of iterations to run gradient descent\n",
        "    print_cost -- if True, print the cost every 1000 iterations\n",
        "    initialization -- flag to choose which initialization to use (\"zeros\",\"random\" or \"he\")\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model\n",
        "    \"\"\"\n",
        "        \n",
        "    grads = {}\n",
        "    costs = [] # to keep track of the loss\n",
        "    m = X.shape[1] # number of examples\n",
        "    layers_dims = [X.shape[0], 10, 5, 1]\n",
        "    \n",
        "    # Initialize parameters dictionary.\n",
        "    if initialization == \"zeros\":\n",
        "        parameters = initialize_parameters_zeros(layers_dims)\n",
        "    elif initialization == \"random\":\n",
        "        parameters = initialize_parameters_random(layers_dims)\n",
        "    elif initialization == \"he\":\n",
        "        parameters = initialize_parameters_he(layers_dims)\n",
        "\n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
        "        a3, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Loss\n",
        "        cost = compute_loss(a3, Y)\n",
        "\n",
        "        # Backward propagation.\n",
        "        grads = backward_propagation(X, Y, cache)\n",
        "        \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        \n",
        "        # Print the loss every 1000 iterations\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the loss\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi38US7QooY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_zeros \n",
        "\n",
        "def initialize_parameters_zeros(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # number of layers in the network\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l - 1]))\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "        ### END CODE HERE ###\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvlxGcr2oobJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "217a198d-8e0c-4c63-c10e-e1aebf0e006a"
      },
      "source": [
        "parameters = initialize_parameters_zeros([3,2,1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 = [[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "b1 = [[0.]\n",
            " [0.]]\n",
            "W2 = [[0. 0.]]\n",
            "b2 = [[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPTZPZrDood3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"zeros\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_SRBwQ2oogp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"predictions_train = \" + str(predictions_train))\n",
        "print(\"predictions_test = \" + str(predictions_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0-vI5znrN-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with Zeros initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5, 1.5])\n",
        "axes.set_ylim([-1.5, 1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKrVjjH-rOBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_random\n",
        "\n",
        "def initialize_parameters_random(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)               # This seed makes sure your \"random\" numbers will be the as ours\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # integer representing the number of layers\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * 10\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae8t889srOIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = initialize_parameters_random([3, 2, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9KyAxs5rOLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"random\")\n",
        "print(\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print(\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdFmfpAZrOG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predictions_train)\n",
        "print(predictions_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrEsXbLwrzIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with large random initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5, 1.5])\n",
        "axes.set_ylim([-1.5, 1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gEdCaYorzMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_he\n",
        "\n",
        "def initialize_parameters_he(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layers_dims) - 1 # integer representing the number of layers\n",
        "     \n",
        "    for l in range(1, L + 1):\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2 / layers_dims[l - 1])\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar8hdkBarzUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = initialize_parameters_he([2, 4, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7aSjekjrzSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"he\")\n",
        "print(\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print(\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XICnJY4VrzQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with He initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5, 1.5])\n",
        "axes.set_ylim([-1.5, 1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eedpRfsarzF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT02rqlgrOD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}